<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Testing strategy for Apache Spark jobs – Part 1 of 2</title>

  <meta name="author" content="" />
  <meta name="keywords" content="">

  

  <meta name="generator" content="Hugo 0.17" />

  <link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel='stylesheet' type='text/css'>

  
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.2/css/bootstrap.min.css">

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/highlight.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/languages/go.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/languages/scala.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/languages/dockerfile.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  
  <script>window.twttr = (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0],
      t = window.twttr || {};
    if (d.getElementById(id)) return t;
    js = d.createElement(s);
    js.id = id;
    js.src = "https://platform.twitter.com/widgets.js";
    fjs.parentNode.insertBefore(js, fjs);

    t._e = [];
    t.ready = function(f) {
      t._e.push(f);
    };

    return t;
  }(document, "script", "twitter-wjs"));</script>

  
  <link href="http://www.raphael-brugier.com/css/animate.css" rel="stylesheet">

  
  
    <link href="http://www.raphael-brugier.com/css/style.default.css" rel="stylesheet" id="theme-stylesheet">
  


  
  <link href="http://www.raphael-brugier.com/css/custom.css" rel="stylesheet">

  
    

  
  <link rel="shortcut icon" href="http://www.raphael-brugier.com/img/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" href="http://www.raphael-brugier.com/img/apple-touch-icon.png" />
  

  <link href="http://www.raphael-brugier.com/css/owl.carousel.css" rel="stylesheet">
  <link href="http://www.raphael-brugier.com/css/owl.theme.css" rel="stylesheet">

  <link rel="alternate" href="http://www.raphael-brugier.com/index.xml" type="application/rss+xml" title="Raphael Brugier">

  
  <meta property="og:title" content="Testing strategy for Apache Spark jobs – Part 1 of 2" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="/blog/testing-strategy-for-apache-spark-jobs-1-of-2//" />
  <meta property="og:image" content="" />

</head>


  <body>

    <div id="all">

        <header>

          <div class="navbar-affixed-top" data-spy="affix" data-offset-top="200">

    <div class="navbar navbar-default yamm" role="navigation" id="navbar">

        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand home" href="http://www.raphael-brugier.com/">
                  <h3>Raphael Brugier</h3>
                </a>
                <div class="navbar-buttons">
                    <button type="button" class="navbar-toggle btn-template-main" data-toggle="collapse" data-target="#navigation">
                        <span class="sr-only">Toggle navigation</span>
                        <i class="fa fa-align-justify"></i>
                    </button>
                </div>
            </div>
            

            <div class="navbar-collapse collapse" id="navigation">
                <ul class="nav navbar-nav navbar-right">
                    
                    <li class="dropdown">
                        <a href="/about/">About</a>
                    </li>
                    

                    
                    <li class="dropdown">
                      <a href="https://twitter.com/rbrugier">
                        <i class="fa fa-twitter fa-2x" aria-hidden="true"></i>
                      </a>
                    </li>
                    
                    <li class="dropdown">
                      <a href="https://www.linkedin.com/in/raphaelbrugier">
                        <i class="fa fa-linkedin fa-2x" aria-hidden="true"></i>
                      </a>
                    </li>
                    
                    <li class="dropdown">
                      <a href="https://github.com/RaphaelBrugier">
                        <i class="fa fa-github fa-2x" aria-hidden="true"></i>
                      </a>
                    </li>
                    
                </ul>
            </div>
            

            <div class="collapse clearfix" id="search">

                <form class="navbar-form" role="search">
                    <div class="input-group">
                        <input type="text" class="form-control" placeholder="Search">
                        <span class="input-group-btn">

                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>

                </span>
                    </div>
                </form>

            </div>
            

        </div>
    </div>
    

</div>




        </header>

        <div id="heading-breadcrumbs">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>Testing strategy for Apache Spark jobs – Part 1 of 2</h1>
            </div>
        </div>
    </div>
</div>


        <div id="content">
            <div class="container">

                <div class="row">

                    

                    <div class="col-md-9" id="blog-post">

                        <p class="text-muted text-uppercase mb-small text-right">March 12, 2016</p>

                        <div id="post-content">
                          <p>Like any other application, Apache Spark jobs deserve good testing practices and coverage.</p>

<p>Indeed, the costs of running jobs with production data makes unit testing a must-do to have a fast feedback loop and discover the errors earlier.</p>

<p>But because of its distributed nature and the RDD abstraction on top of the data, Spark requires special care for testing.</p>

<p>In this post, we’ll explore how to design your code for testing, how to setup a simple unit-test for your job logic and how the <a href="https://github.com/holdenk/spark-testing-base">spark-testing-base</a> library can help.</p>

<p></p>

<h1 id="design-for-testing">Design for testing</h1>

<p>From a higher point of view, any Spark job can be described as an “immutable” a transformation of distributed data.</p>

<p>In particular, any Spark job can be refactored to a composition of functions taking data as input, the so-called RDD, and returning data, hence a RDD again.</p>

<p>Extracting the logic of the job into functions will make it possible to reuse the functions across different jobs and to isolate the behavior to test it in a deterministic environment.</p>

<p>To separate the logic from the scheduling and configuration of the job, you will also want to isolate the logic to a separated object.</p>

<p>Let’s apply this pattern to the well-known word count example.</p>

<pre><code class="language-scala">package com.ipponusa
import org.apache.spark.{SparkConf, SparkContext}

object Main {

  val sparkConf = new SparkConf()
    .setMaster(&quot;local[*]&quot;)
    .setAppName(&quot;spark-testing-example&quot;)
  val sc = new SparkContext(sparkConf)

  def main(args: Array[String]) {
    val countByWordRdd =  sc.textFile(&quot;src/main/resources/intro.txt&quot;)
      .flatMap(l =&gt; l.split(&quot;\\W+&quot;))
      .map(word =&gt; (word, 1))
      .reduceByKey(_ + _)

    countByWordRdd.foreach(println)
  }
}
</code></pre>

<p>Extracting a method is a <a href="http://refactoring.com/catalog/extractMethod.html">classic refactoring pattern</a>. Therefore, this can be easily done with a few keystrokes within your favorite IDE:</p>

<ol>
<li>Extract the input data in a separated variable to separate it from the logic</li>
<li>Extract the logic in a count method (select + refactor -&gt; extract -&gt; method)</li>
<li>Move the method to a new object, WordCounter</li>
</ol>

<pre><code class="language-scala">package com.ipponusa
import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}

object Main {

  val sparkConf = new SparkConf()
    .setMaster(&quot;local[*]&quot;)
    .setAppName(&quot;spark-testing-example&quot;)
  val sc = new SparkContext(sparkConf)

  def main(args: Array[String]) {
    val input: RDD[String] = sc.textFile(&quot;src/main/resources/intro.txt&quot;)
    val countByWordRdd: RDD[(String, Int)] = WordCounter.count(input)

    countByWordRdd.foreach(println)
  }
}
</code></pre>

<pre><code class="language-scala">package com.ipponusa
import org.apache.spark.rdd.RDD

object WordCounter {
  def count(lines: RDD[String]): RDD[(String, Int)] = {
    val wordsCount = lines.flatMap(l =&gt; l.split(&quot;\\W+&quot;))
      .map(word =&gt; (word, 1))
      .reduceByKey(_ + _)
    wordsCount
  }
}
</code></pre>

<h1 id="basic-test">Basic test</h1>

<p>Now that we have extracted the logic, we can write a test assuming an input data and asserting the result of the function to an expected data. We will use <a href="http://www.scalatest.org/">ScalaTest</a> as a testing framework.</p>

<p>The tricky part when writing tests for Spark is the RDD abstraction. Your first idea would probably be to mock the input and the expected. But then, you will not be able to execute the Spark behavior on the RDD passed to the function.</p>

<p>Instead, we have to start a <code>SparkContext</code> to build the input and expected RDDs and run the transformation in a real Spark environment. Indeed, creating a <code>SparkContext</code> for unit testing is the <a href="http://spark.apache.org/docs/latest/programming-guide.html#unit-testing">recommended approach</a>.</p>

<p>Because starting a <code>SparkContext</code> is time-consuming, you will save a lot of time starting the context only once before all the tests. Also, even if it possible with some tweaking, it is not recommended to have more than one <code>SparkContext</code> living in the JVM. So make sure you stop the context after running all the tests and to disable the parallel execution.</p>

<p>Starting and stopping the <code>SparkContext</code> can easily be done with the <code>BeforeAndAfter</code> trait.</p>

<pre><code class="language-scala">package com.ipponusa
import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}
import org.scalatest.{BeforeAndAfter, FlatSpec, Matchers}

class WordCounterTest extends FlatSpec with Matchers with BeforeAndAfter {

  var sc:SparkContext = _

  before {
    val sparkConf = new SparkConf()
      .setMaster(&quot;local[*]&quot;)
      .setAppName(&quot;test-wordcount&quot;)
    sc = new SparkContext(sparkConf)
  }

  after {
    sc.stop()
  }

  behavior of &quot;Words counter&quot;

  it should &quot;count words in a text&quot; in {
    val text =
      &quot;&quot;&quot;Hello Spark
        |Hello world
      &quot;&quot;&quot;.stripMargin
    val lines: RDD[String] = sc.parallelize(List(text))
    val wordCounts: RDD[(String, Int)] = WordCounter.count(lines)

    wordCounts.collect() should contain allOf ((&quot;Hello&quot;, 2), (&quot;Spark&quot;, 1), (&quot;world&quot;, 1))
  }
}
</code></pre>

<h1 id="spark-testing-base-library">Spark-testing-base library</h1>

<p>Setting up the <code>before</code> and <code>after</code> methods for all your test cases can become tedious if you have many tests. An alternative could be to hold the Context in a Singleton Object and start it once for all the tests, or to inherits a common trait to implement this behavior.</p>

<p>Also, the previous example works fine when working with a local cluster where all the data can fit in memory.
But if you are testing with a lot of data, a large sample of your production data for example, calling the <code>collect()</code> method to gather all the data locally to compare with an expected output is no longer an option.</p>

<p>Fortunately, the spark-testing-base library provides traits and methods to prepare your tests and run distributed comparisons.</p>

<p>Let’s import the library and rewrite the test:</p>

<p><code>pom.xml</code> extract:</p>

<pre><code class="language-xml">&lt;dependencies&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
    &lt;artifactId&gt;spark-core_${scala.dep.version}&lt;/artifactId&gt;
    &lt;version&gt;${spark.version}&lt;/version&gt;
  &lt;/dependency&gt;
  &lt;!--spark-testing has a dependency to spark-sql, spark-hive, spark-mllib --&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
    &lt;artifactId&gt;spark-sql_${scala.dep.version}&lt;/artifactId&gt;
    &lt;version&gt;${spark.version}&lt;/version&gt;
  &lt;/dependency&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
    &lt;artifactId&gt;spark-hive_${scala.dep.version}&lt;/artifactId&gt;
    &lt;version&gt;${spark.version}&lt;/version&gt;
  &lt;/dependency&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
    &lt;artifactId&gt;spark-mllib_${scala.dep.version}&lt;/artifactId&gt;
    &lt;version&gt;${spark.version}&lt;/version&gt;
  &lt;/dependency&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org.scalatest&lt;/groupId&gt;
    &lt;artifactId&gt;scalatest_${scala.dep.version}&lt;/artifactId&gt;
    &lt;version&gt;2.2.6&lt;/version&gt;
    &lt;scope&gt;test&lt;/scope&gt;
  &lt;/dependency&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;com.holdenkarau&lt;/groupId&gt;
    &lt;artifactId&gt;spark-testing-base_${scala.dep.version}&lt;/artifactId&gt;
    &lt;version&gt;${spark.version}_0.3.2-SNAPSHOT&lt;/version&gt;
  &lt;scope&gt;test&lt;/scope&gt;
  &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>

<pre><code class="language-scala">package com.ipponusa
import com.holdenkarau.spark.testing.{RDDComparisons, RDDGenerator, SharedSparkContext}
import org.apache.spark.rdd.RDD
import org.scalacheck.Arbitrary
import org.scalacheck.Prop._
import org.scalatest.prop.Checkers
import org.scalatest.{FlatSpec, Matchers}

@RunWith(classOf[JUnitRunner])
class WordCounterWithSparkTestingTest extends FlatSpec with Matchers with SharedSparkContext{

  behavior of &quot;Words counter&quot;

  it should &quot;count words in a text&quot; in {
    val text =
      &quot;&quot;&quot;Hello Spark
        |Hello world
      &quot;&quot;&quot;.stripMargin

    val inputRdd: RDD[String] = sc.parallelize(List(text))
    val expectedRdd: RDD[(String, Int)] = sc.parallelize(List((&quot;Hello&quot;, 2), (&quot;Spark&quot;, 1), (&quot;world&quot;, 1)))

    val resRdd: RDD[(String, Int)] = WordCounter.count(inputRdd)
    assert(None === RDDComparisons.compare(resRdd, expectedRdd))
  }
}
</code></pre>

<p>The test class now extends the <code>SharedSparkContext</code> trait instead of <code>BeforeAndAfter</code>. This trait will automatically take care of starting and stopping a <code>SparkContext</code> for you.</p>

<p>The method RDDComparisons.compare(…) is more interesting.</p>

<p>Instead of locally collecting the data to be compared, the comparison will be run as RDD operations on Spark nodes. Even if this may involve a lot of shuffling operations, the data is still distributed and thus can fit in memory.</p>

<p>Of course, in the same manner, the input and expected data would not be loaded locally but most probably from external distributed storage.</p>

<p>Like HDFS for example:</p>

<pre><code class="language-scala">val inputRdd = sc.textFile(&quot;hdfs://127.0.0.1:9000/data/test/bigInput.txt&quot;)
val expectedRdd = sc.textFile(&quot;hdfs://127.0.0.1:9000/data/test/bigExpected.txt&quot;)
</code></pre>

<p>The spark-testing-base library also provides methods for property-based testing via an integration of the <a href="https://www.scalacheck.org/">ScalaCheck</a> library.</p>

<pre><code class="language-scala">class WordCounterWithSparkTestingTest extends FlatSpec with Matchers with SharedSparkContext with Checkers {

  behavior of &quot;Words counter&quot;
  
  it should &quot;have stable count, with generated RDDs&quot; in {
     val stableProperty =
       forAll(RDDGenerator.genRDD[String](sc)(Arbitrary.arbitrary[String])) {
         rdd =&gt; None === RDDComparisons.compare(WordCounter.count(rdd), WordCounter.count(rdd))
       }
     check(stableProperty)
   }
}
</code></pre>

<p>Here, <code>RddGenerator.genRDD[String]</code> will generate RDDs on top of random Strings.</p>

<p>We declare the property to have the same count result when executing twice the method.</p>

<p>We then test the property with the ScalaCheck method.</p>

<p>While not very relevant for the wordcount example, it allows to test your job logic against randomly generated data as input and therefore test the reliability of your code.</p>

<h1 id="conclusion">Conclusion</h1>

<p>In this article, we have seen how it is possible to refactor and test a Spark job. Testing your jobs will allow faster feedback when implementing them and you can even practice TDD.</p>

<p>The next step would be to run the tests not only on a local cluster, but on a “production-like” cluster with more data on your continuous integration server. Simply override the <code>setMaster()</code> value when configuring the <code>SparkContext</code> to redirect to your test cluster.</p>

<p>Finally, I definitely recommend you watch Holden Karau’s session on testing Spark recorded at the last Spark Summit (<a href="https://www.youtube.com/watch?v=rOQEiTXNS0g">video</a>, <a href="http://www.slideshare.net/SparkSummit/beyond-parallelize-and-collect-by-holden-karau">slides</a>).
You can find the code for these examples <a href="https://github.com/raphaelbrugier/spark-testing-example">on Github</a>.</p>
                        </div>
                        <div>
                          <a class="twitter-share-button"
                             href="https://twitter.com/intent/tweet?via=rbrugier&hashtags=Apache%20Spark,testing,"
                             data-size="large">
                          </a>
                        </div>
                        
                        
                        <div id="comments">
                            <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'raphaelbrugierblog';
    var disqus_identifier = 'http:\/\/www.raphael-brugier.com\/blog\/testing-strategy-for-apache-spark-jobs-1-of-2\/';
    var disqus_title = 'Testing strategy for Apache Spark jobs – Part 1 of 2';
    var disqus_url = 'http:\/\/www.raphael-brugier.com\/blog\/testing-strategy-for-apache-spark-jobs-1-of-2\/';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
                        </div>
                        

                    </div>
                    

                    

                    

                    <div class="col-md-3">

                        

                        

<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
        <h3 class="panel-title">Search</h3>
    </div>

    <div class="panel-body">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" role="search">
            <div class="input-group">
                <input type="search" name="q" results="0" class="form-control" placeholder="Search">
                <input type="hidden" name="q" value="site:http://www.raphael-brugier.com/">
                <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>
                </span>
            </div>
        </form>
    </div>
</div>











                        

                    </div>
                    

                    

                </div>
                

            </div>
            
        </div>
        

        <footer id="footer">
    <div class="container">

        

        <div class="col-md-4 col-sm-6">

            <h4>Recent posts</h4>

            <div class="blog-entries">
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="http://www.raphael-brugier.com/blog/using-docker-to-simplify-cassandra-development-in-jhipster/">
                          
                            <img src="http://www.raphael-brugier.com/img/logo-jhipster.png" class="img-responsive" alt="">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="http://www.raphael-brugier.com/blog/using-docker-to-simplify-cassandra-development-in-jhipster/">Using Docker to simplify Cassandra development in JHipster</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="http://www.raphael-brugier.com/blog/a-tour-of-databricks-community-edition-a-hosted-spark-service/">
                          
                            <img src="http://www.raphael-brugier.com/img/spark-logo.png" class="img-responsive" alt="">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="http://www.raphael-brugier.com/blog/a-tour-of-databricks-community-edition-a-hosted-spark-service/">A tour of Databricks Community Edition: a hosted Spark service</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="http://www.raphael-brugier.com/blog/testing-strategy-for-apache-spark-jobs-2-of-2/">
                          
                            <img src="http://www.raphael-brugier.com/img/spark-logo.png" class="img-responsive" alt="">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="http://www.raphael-brugier.com/blog/testing-strategy-for-apache-spark-jobs-2-of-2/">Testing strategy for Spark Streaming – Part 2 of 2</a></h5>
                    </div>
                </div>
                
            </div>

            <hr class="hidden-md hidden-lg">

        </div>
        

        

    </div>
    
</footer>







<div id="copyright">
    <div class="container">
        <div class="col-md-12">
            
            <p class="pull-right">
              Template by <a href="http://bootstrapious.com/free-templates">Bootstrapious</a>.
              

              Ported to Hugo by <a href="https://github.com/devcows/hugo-universal-theme">DevCows</a>
            </p>
        </div>
    </div>
</div>





    </div>
    

    
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-3393491-2', 'auto');
ga('send', 'pageview');
</script>

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.2/js/bootstrap.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/waypoints/2.0.5/waypoints.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js"></script>
<script src="//maps.googleapis.com/maps/api/js?v=3.exp"></script>
<script src="http://www.raphael-brugier.com/js/hpneo.gmaps.js"></script>
<script src="http://www.raphael-brugier.com/js/gmaps.init.js"></script>
<script src="http://www.raphael-brugier.com/js/front.js"></script>


<script src="http://www.raphael-brugier.com/js/owl.carousel.min.js"></script>


  </body>
</html>
