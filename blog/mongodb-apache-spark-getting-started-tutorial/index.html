<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>MongoDB and Apache Spark - Getting started tutorial</title>

  <meta name="author" content="" />
  <meta name="keywords" content="">

  

  <meta name="generator" content="Hugo 0.17" />

  <link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel='stylesheet' type='text/css'>

  
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.2/css/bootstrap.min.css">

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/highlight.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/languages/go.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/languages/scala.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.6.0/languages/dockerfile.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  
  <script>window.twttr = (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0],
      t = window.twttr || {};
    if (d.getElementById(id)) return t;
    js = d.createElement(s);
    js.id = id;
    js.src = "https://platform.twitter.com/widgets.js";
    fjs.parentNode.insertBefore(js, fjs);

    t._e = [];
    t.ready = function(f) {
      t._e.push(f);
    };

    return t;
  }(document, "script", "twitter-wjs"));</script>

  
  <link href="http://www.raphael-brugier.com/css/animate.css" rel="stylesheet">

  
  
    <link href="http://www.raphael-brugier.com/css/style.default.css" rel="stylesheet" id="theme-stylesheet">
  


  
  <link href="http://www.raphael-brugier.com/css/custom.css" rel="stylesheet">

  
    

  
  <link rel="shortcut icon" href="http://www.raphael-brugier.com/img/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" href="http://www.raphael-brugier.com/img/apple-touch-icon.png" />
  

  <link href="http://www.raphael-brugier.com/css/owl.carousel.css" rel="stylesheet">
  <link href="http://www.raphael-brugier.com/css/owl.theme.css" rel="stylesheet">

  <link rel="alternate" href="http://www.raphael-brugier.com/index.xml" type="application/rss+xml" title="Raphael Brugier">

  
  <meta property="og:title" content="MongoDB and Apache Spark - Getting started tutorial" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="/blog/mongodb-apache-spark-getting-started-tutorial//" />
  <meta property="og:image" content="" />

</head>


  <body>

    <div id="all">

        <header>

          <div class="navbar-affixed-top" data-spy="affix" data-offset-top="200">

    <div class="navbar navbar-default yamm" role="navigation" id="navbar">

        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand home" href="http://www.raphael-brugier.com/">
                  <h3>Raphael Brugier</h3>
                </a>
                <div class="navbar-buttons">
                    <button type="button" class="navbar-toggle btn-template-main" data-toggle="collapse" data-target="#navigation">
                        <span class="sr-only">Toggle navigation</span>
                        <i class="fa fa-align-justify"></i>
                    </button>
                </div>
            </div>
            

            <div class="navbar-collapse collapse" id="navigation">
                <ul class="nav navbar-nav navbar-right">
                    
                    <li class="dropdown">
                        <a href="/about/">About</a>
                    </li>
                    

                    
                    <li class="dropdown">
                      <a href="https://twitter.com/rbrugier">
                        <i class="fa fa-twitter fa-2x" aria-hidden="true"></i>
                      </a>
                    </li>
                    
                    <li class="dropdown">
                      <a href="https://www.linkedin.com/in/raphaelbrugier">
                        <i class="fa fa-linkedin fa-2x" aria-hidden="true"></i>
                      </a>
                    </li>
                    
                    <li class="dropdown">
                      <a href="https://github.com/RaphaelBrugier">
                        <i class="fa fa-github fa-2x" aria-hidden="true"></i>
                      </a>
                    </li>
                    
                </ul>
            </div>
            

            <div class="collapse clearfix" id="search">

                <form class="navbar-form" role="search">
                    <div class="input-group">
                        <input type="text" class="form-control" placeholder="Search">
                        <span class="input-group-btn">

                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>

                </span>
                    </div>
                </form>

            </div>
            

        </div>
    </div>
    

</div>




        </header>

        <div id="heading-breadcrumbs">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>MongoDB and Apache Spark - Getting started tutorial</h1>
            </div>
        </div>
    </div>
</div>


        <div id="content">
            <div class="container">

                <div class="row">

                    

                    <div class="col-md-9" id="blog-post">

                        <p class="text-muted text-uppercase mb-small text-right">May 3, 2017</p>

                        <div id="post-content">
                          <p>MongoDB and Apache Spark are two popular Big Data technologies.</p>

<p>In my <a href="/blog/introduction-mongodb-spark-connector/">previous post</a>, I listed the capabilities of the <a href="https://docs.mongodb.com/spark-connector/v2.0/">MongoDB connector for Spark</a>. In this tutorial, I will show you how to configure Spark to connect to MongoDB, load data, and write queries.</p>

<p>To demonstrate how to use Spark with MongoDB, I will use the zip codes from MongoDB tutorial on <a href="https://docs.mongodb.com/v3.2/tutorial/aggregation-zip-code-data-set/">the aggregation pipeline documentation using a zip code data set</a>. I have prepared a Maven project and a Docker Compose file to get you started quickly.</p>

<p></p>

<h2 id="prerequisites">Prerequisites</h2>

<ul>
<li>Install <a href="https://docs.docker.com/engine/installation/">Docker and Docker Compose</a></li>
<li>Install Maven</li>
<li>Download the project <a href="https://github.com/raphaelbrugier/spark-mongo-example">from Github</a></li>
</ul>

<p>From the project root, launch the MongoDB server with docker-compose:
<code>docker-compose -f docker/docker-compose.yml up -d</code></p>

<p>Import the data in the MongoDB database running in the container:
<code>docker exec -it mongo_container sh /scripts/import-data.sh</code></p>

<p>Check that the data has been loaded in MongoDB by connecting to the container and running a count:
<code>docker exec mongo_container mongo --eval &quot;db.zips.count()&quot;</code></p>

<p>This should return:</p>

<pre><code class="language-bash">MongoDB shell version: 3.2.11
connecting to: test
29353
</code></pre>

<p>The zips collection is a collection of <em>Document</em> with the following model:</p>

<pre><code class="language-json">{
  &quot;_id&quot;: &quot;10280&quot;,
  &quot;city&quot;: &quot;NEW YORK&quot;,
  &quot;state&quot;: &quot;NY&quot;,
  &quot;pop&quot;: 5574,
  &quot;loc&quot;: [
    -74.016323,
    40.710537
  ]
}
</code></pre>

<p>Import the Maven project in your favorite IDE. Create a new file <em>Main.scala</em> to copy the examples or run the <code>MongoSparkMain</code> for the solution.</p>

<h2 id="read-data-from-mongodb-to-spark">Read data from MongoDB to Spark</h2>

<p>In this example, we will see how to configure the connector and read from a MongoDB collection to a DataFrame.</p>

<p>First, you need to create a minimal SparkContext, and then to configure the <code>ReadConfig</code> instance used by the connector with the MongoDB URL, the name of the database and the collection to load:</p>

<pre><code class="language-scala">import com.mongodb.spark._
import com.mongodb.spark.config.ReadConfig
import com.mongodb.spark.sql._
import com.typesafe.scalalogging.slf4j.LazyLogging
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.{max, min}
import org.bson.Document

object Main extends App with LazyLogging {
    val spark = SparkSession.builder()
    .appName(&quot;mongozips&quot;)
    .master(&quot;local[*]&quot;)
    .getOrCreate()

  // Read the data from MongoDB to a DataFrame
  val readConfig = ReadConfig(Map(&quot;uri&quot; -&gt; &quot;mongodb://127.0.0.1/&quot;, &quot;database&quot; -&gt; &quot;test&quot;, &quot;collection&quot; -&gt; &quot;zips&quot;)) // 1)
  val zipDf = spark.read.mongo(readConfig) // 2)
  zipDf.printSchema() // 3)
  zipDf.show()
}
</code></pre>

<ol>
<li>Set the MongoDB URL, database, and collection to read.</li>
<li>The connector provides a method to convert a MongoRDD to a DataFrame. The DataFrame’s schema is automatically inferred by the connector by <a href="https://docs.mongodb.com/v3.2/reference/operator/aggregation/sample/">sampling</a> the collection. Alternatively, you can explicitly pass a schema definition.</li>
<li>Print the schema inferred by the connector.</li>
</ol>

<p>Results:</p>

<pre><code class="language-text">root
 |-- _id: string (nullable = true)
 |-- city: string (nullable = true)
 |-- loc: array (nullable = true)
 |    |-- element: double (containsNull = true)
 |-- pop: integer (nullable = true)
 |-- state: string (nullable = true)

+-----+-----------+--------------------+-----+-----+
|  _id|       city|                 loc|  pop|state|
+-----+-----------+--------------------+-----+-----+
|01001|     AGAWAM|[-72.622739, 42.0...|15338|   MA|
|01002|    CUSHMAN|[-72.51565, 42.37...|36963|   MA|
|01005|      BARRE|[-72.108354, 42.4...| 4546|   MA|
|01007|BELCHERTOWN|[-72.410953, 42.2...|10579|   MA|
|01008|  BLANDFORD|[-72.936114, 42.1...| 1240|   MA|
+-----+-----------+--------------------+-----+-----+
only showing top 5 rows
</code></pre>

<p>The connector has correctly inferred the schema based on the documents sampling. Both the column names and types have been identified accurately.</p>

<h3 id="inferring-inner-documents">Inferring inner-documents</h3>

<p>Interestingly, the <code>loc</code> array from the MongoDB document has been translated to a Spark’s Array type.</p>

<p>But what if the document contains inner documents? The connector does not flatten the inner document but translates them as a Spark’s StructType, a key-value type.</p>

<p>Take for example this MongoDB document:</p>

<pre><code class="language-json">{
  name: &quot;Joe Bookreader&quot;,
  country: {
    isocode: &quot;USA&quot;,
    name: &quot;United States&quot;
  },
  addresses: [
    {
      street: &quot;123 Fake Street&quot;,
      city: &quot;Faketon&quot;,
      state: &quot;MA&quot;,
      zip: &quot;12345&quot;
    }
  ]
}
</code></pre>

<p>The document has two inner documents. The first one is the country and the second one is an address contained in a list.</p>

<p>After loading the collections, the schema inferred by the connector shows a StructType for both the <code>country</code> and the <code>address</code> in the array of addresses.</p>

<pre><code class="language-scala">val personDf = spark.read.mongo(ReadConfig(Map(&quot;uri&quot; -&gt; &quot;mongodb://127.0.0.1/&quot;, &quot;database&quot; -&gt; &quot;test&quot;, &quot;collection&quot; -&gt; &quot;person&quot;)))
personDf.printSchema()
</code></pre>

<p>Results:</p>

<pre><code class="language-text">root
 |-- _id: struct (nullable = true)
 |    |-- oid: string (nullable = true)
 |-- addresses: array (nullable = true)
 |    |-- element: struct (containsNull = true)
 |    |    |-- street: string (nullable = true)
 |    |    |-- city: string (nullable = true)
 |    |    |-- state: string (nullable = true)
 |    |    |-- zip: string (nullable = true)
 |-- country: struct (nullable = true)
 |    |-- isocode: string (nullable = true)
 |    |-- name: string (nullable = true)
 |-- name: string (nullable = true)
</code></pre>

<p>The values in the StructType types can be accessed by their column names:</p>

<pre><code class="language-scala">personDf.select($&quot;_id&quot;, $&quot;addresses&quot;(0)(&quot;street&quot;), $&quot;country&quot;(&quot;name&quot;))
</code></pre>

<p>You can find the list of the mappings between the MongoDB types and the DataFrame’s types in the <a href="https://docs.mongodb.com/spark-connector/v2.0/scala/datasets-and-sql/#datatypes">connector&rsquo;s documentation</a>.</p>

<h2 id="use-the-spark-api-to-query-the-data">Use the Spark API to query the data</h2>

<p>After loading the collection in a DataFrame, we can now use the Spark API to query and transform the data.</p>

<p>As an example, we write a query to find the states with a population greater or equal to 10 million. The example also shows how the Spark API can easily map to the original MongoDB query.</p>

<p>The MongoDB query is:</p>

<pre><code class="language-scala">db.zipcodes.aggregate( [
   { $group: { _id: &quot;$state&quot;, totalPop: { $sum: &quot;$pop&quot; } } },
   { $match: { totalPop: { $gte: 10*1000*1000 } } }
] )
</code></pre>

<p>And now the Spark query:</p>

<pre><code class="language-scala">println( &quot;States with Populations above 10 Million&quot; )
import zipDf.sqlContext.implicits._ // 1)
zipDf.groupBy(&quot;state&quot;)
    .sum(&quot;pop&quot;)
    .withColumnRenamed(&quot;sum(pop)&quot;, &quot;count&quot;) // 2)
    .filter($&quot;count&quot; &gt; 10000000)
    .show()
</code></pre>

<p>Result:</p>

<pre><code class="language-text">States with Populations above 10 Millions:
+-----+--------+
|state|   count|
+-----+--------+
|   TX|16984601|
|   NY|17990402|
|   OH|10846517|
|   IL|11427576|
|   CA|29754890|
|   PA|11881643|
|   FL|12686644|
+-----+--------+
</code></pre>

<p>The DataFrame API is pretty straight forward for this simple query.</p>

<ol>
<li>Use the import to have implicit conversions from <code>String</code> to <code>Column</code> with the <code>$</code>.</li>
<li>Rename the result of the sum column for readability.</li>
</ol>

<h2 id="spark-sql">Spark SQL</h2>

<p>Spark and the DataFrame abstraction also enables to write plain Spark SQL queries with a familiar SQL syntax.</p>

<p>For example, let’s rewrite the previous query with SQL:</p>

<pre><code class="language-scala">// SparkSQL:
  zipDf.createOrReplaceTempView(&quot;zips&quot;) // 1)
  zipDf.sqlContext.sql( // 2)
    &quot;&quot;&quot;SELECT state, sum(pop) AS count
      FROM zips
      GROUP BY state
      HAVING sum(pop) &gt; 10000000&quot;&quot;&quot;
  )
  .show()
</code></pre>

<ol>
<li>Register the DataFrame as a Spark SQL table.</li>
<li>Execute the Spark SQL query.</li>
</ol>

<h2 id="predicates-pushdown">Predicates pushdown</h2>

<p><em>“Predicates pushdown”</em> is an optimization from the connector and the Catalyst optimizer to automatically “push down” predicates to the data nodes. The goal is to maximize the amount of data filtered out on the data storage side before loading it into Spark’s node memory.</p>

<p>There are two kinds of predicates automatically pushed down by the connector to MongoDB:</p>

<ul>
<li>the <code>select</code> clause (projections) as a <a href="https://docs.mongodb.com/manual/reference/operator/aggregation/project/"><code>$project</code></a></li>
<li>the <code>filter</code> clause content (<code>where</code>) as one or more <a href="https://docs.mongodb.com/manual/reference/operator/aggregation/match/"><code>$match</code></a></li>
</ul>

<p>Both are sent by the connector as an <a href="https://github.com/mongodb/mongo-spark/blob/master/src/main/scala/com/mongodb/spark/sql/MongoRelationHelper.scala#L30">aggregation pipeline</a>.</p>

<p>To verify if the predicates are sent, we use the Spark’s <em>explain</em> method to examine the query plan produced by Spark for a simple query with a filter:</p>

<pre><code class="language-scala">zipDf
    .filter($&quot;pop&quot; &gt; 0)
    .select(&quot;state&quot;)
    .explain(true)
</code></pre>

<p>Output:</p>

<pre><code class="language-text">== Parsed Logical Plan ==
[...]

== Analyzed Logical Plan ==
[...]

== Optimized Logical Plan ==
[...]

== Physical Plan ==
*Project [state#4]
+- *Filter (isnotnull(pop#3) &amp;&amp; (pop#3 &gt; 0))
   +- *Scan MongoRelation(MongoRDD[0] at RDD at MongoRDD.scala:52,Some(StructType(StructField(_id,StringType,true), StructField(city,StringType,true), StructField(loc,ArrayType(DoubleType,true),true), StructField(pop,IntegerType,true), StructField(state,StringType,true)))) [state#4,pop#3] PushedFilters: [IsNotNull(pop), GreaterThan(pop,0)], ReadSchema: struct&lt;state:string&gt;
</code></pre>

<p>We can see in the physical plan generated by the Catalyst optimizer, the name of the fields to project (<code>state</code> and <code>pop</code>), and the filters to push (pop not null and pop greater than 0).</p>

<p>To confirm what is actually executed on the MongoDB nodes, we need to increase MongoDB’s log level and examine the <code>system.profile</code> collection.</p>

<p>Enable the logging on MongoDB, run the Spark query again, and find the trace of the query in the <code>system.profile</code> collection:</p>

<pre><code class="language-bash">$mongo
MongoDB shell version: 3.2.11
connecting to: test

&gt; db.setProfilingLevel(2)
&gt; db.system.profile.find().pretty()
</code></pre>

<p>The result is:</p>

<pre><code class="language-json">{
	&quot;op&quot; : &quot;command&quot;,
	&quot;ns&quot; : &quot;test.zips&quot;,
	&quot;command&quot; : {
		&quot;aggregate&quot; : &quot;zips&quot;,
		&quot;pipeline&quot; : [
			{
				&quot;$match&quot; : {
					&quot;_id&quot; : {
						&quot;$gte&quot; : { &quot;$minKey&quot; : 1 },
						&quot;$lt&quot; : { &quot;$maxKey&quot; : 1 }
					}
				}
			},
			{
				&quot;$match&quot; : {
					&quot;pop&quot; : {
						&quot;$exists&quot; : true,
						&quot;$ne&quot; : null,
						&quot;$gt&quot; : 0
					}
				}
			},
			{
				&quot;$project&quot; : {
					&quot;state&quot; : 1,
					&quot;pop&quot; : 1,
					&quot;_id&quot; : 0
				}
			}
		],
		&quot;cursor&quot; : {

		},
		&quot;allowDiskUse&quot; : true
	},
	[...]
}
</code></pre>

<p>The result shows the <code>$project</code> and <code>$match</code> clauses executed by MongoDB and, as expected, they match the Spark’s physical plan.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this article, I have shown how to connect to a MongoDB database with Apache Spark to load and query the data. The connector provides a set of utility methods to easily load data from MongoDB to a DataFrame.</p>

<p>I have also presented how a MongoDB <em>Document</em> is mapped to a Spark’s DataFrame. Because of the hierarchical nature of a <em>Document</em>, only the first level of attributes is mapped to columns. Inner documents become nested columns.</p>

<p>Finally, I have described how the connector minimizes the data loaded in Spark by taking advantage of the predicates pushdown optimization, an essential feature of every connector. The connector does a good job of sending the predicates automatically, but it is helpful to know how to confirm if and how the predicates are applied on the MongoDB side.</p>

<p>In conclusion, the connector is fully functional to take benefit from using Spark on top of MongoDB.</p>
                        </div>
                        <div>
                          <a class="twitter-share-button"
                             href="https://twitter.com/intent/tweet?via=rbrugier&hashtags=Apache%20Spark,MongoDB,"
                             data-size="large">
                          </a>
                        </div>
                        
                        
                        <div id="comments">
                            <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'raphaelbrugierblog';
    var disqus_identifier = 'http:\/\/www.raphael-brugier.com\/blog\/mongodb-apache-spark-getting-started-tutorial\/';
    var disqus_title = 'MongoDB and Apache Spark - Getting started tutorial';
    var disqus_url = 'http:\/\/www.raphael-brugier.com\/blog\/mongodb-apache-spark-getting-started-tutorial\/';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
                        </div>
                        

                    </div>
                    

                    

                    

                    <div class="col-md-3">

                        

                        

<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
        <h3 class="panel-title">Search</h3>
    </div>

    <div class="panel-body">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" role="search">
            <div class="input-group">
                <input type="search" name="q" results="0" class="form-control" placeholder="Search">
                <input type="hidden" name="q" value="site:http://www.raphael-brugier.com/">
                <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>
                </span>
            </div>
        </form>
    </div>
</div>











                        

                    </div>
                    

                    

                </div>
                

            </div>
            
        </div>
        

        <footer id="footer">
    <div class="container">

        

        <div class="col-md-4 col-sm-6">

            <h4>Recent posts</h4>

            <div class="blog-entries">
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="http://www.raphael-brugier.com/blog/fix-git-completion-zsh-mac-homebrew/">
                          
                            <img src="http://www.raphael-brugier.com/img/banners/git-logo.svg" class="img-responsive" alt="">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="http://www.raphael-brugier.com/blog/fix-git-completion-zsh-mac-homebrew/">Fix the Git completion with Oh-my-Zsh on Mac</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="http://www.raphael-brugier.com/blog/mongodb-apache-spark-getting-started-tutorial/">
                          
                            <img src="http://www.raphael-brugier.com/img/spark-logo.png" class="img-responsive" alt="">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="http://www.raphael-brugier.com/blog/mongodb-apache-spark-getting-started-tutorial/">MongoDB and Apache Spark - Getting started tutorial</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="http://www.raphael-brugier.com/blog/introduction-mongodb-spark-connector/">
                          
                            <img src="http://www.raphael-brugier.com/img/spark-logo.png" class="img-responsive" alt="">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="http://www.raphael-brugier.com/blog/introduction-mongodb-spark-connector/">Introduction to the MongoDB connector for Apache Spark</a></h5>
                    </div>
                </div>
                
            </div>

            <hr class="hidden-md hidden-lg">

        </div>
        

        

    </div>
    
</footer>







<div id="copyright">
    <div class="container">
        <div class="col-md-12">
            
            <p class="pull-right">
              Template by <a href="http://bootstrapious.com/free-templates">Bootstrapious</a>.
              

              Ported to Hugo by <a href="https://github.com/devcows/hugo-universal-theme">DevCows</a>
            </p>
        </div>
    </div>
</div>





    </div>
    

    
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-3393491-2', 'auto');
ga('send', 'pageview');
</script>

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.2/js/bootstrap.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/waypoints/2.0.5/waypoints.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js"></script>
<script src="//maps.googleapis.com/maps/api/js?v=3.exp"></script>
<script src="http://www.raphael-brugier.com/js/hpneo.gmaps.js"></script>
<script src="http://www.raphael-brugier.com/js/gmaps.init.js"></script>
<script src="http://www.raphael-brugier.com/js/front.js"></script>


<script src="http://www.raphael-brugier.com/js/owl.carousel.min.js"></script>


  </body>
</html>
